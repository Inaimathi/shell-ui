#!/usr/bin/python

import sys, os, re, time
import urllib, requests, cssselect, lxml.html
import logging

from optparse import OptionParser
from subprocess import call

logging.basicConfig()
log = logging.getLogger("picstream")

headers = {
    'Connection': "keep-alive",
    'Cache-Control': "max-age=0",
    'User-Agent': "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.4 (KHTML, like Gecko) Chrome/22.0.1229.94 Safari/537.4",
    'Accept': "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    'Accept-Encoding': "gzip,deflate,sdch",
    'Accept-Language': "en-US,en;q=0.8",
    'Accept-Charset': "ISO-8859-1,utf-8;q=0.7,*;q=0.3"
}

ipad_headers = {k: v if not k=='User-Agent' else "Mozilla/5.0 (iPad; U; CPU OS 3_2 like Mac OS X; en-us) AppleWebKit/531.21.10 (KHTML, like Gecko) Version/4.0.4 Mobile/7B334b Safari/531.21.10')" for k, v in headers.iteritems()}

def getStream(uri, desired, nextLink=False, headers=headers, delay=False):
    cookies = {}
    cur_uri = uri
    while cur_uri:
        pg = __getHtml(cur_uri, cookies=cookies, headers=headers)
        uri_base = uri.split("/")[0:3]
        ## yield cleaned URI
        ##   (we need to handle relative, absolute, protocol-defaulting AND full URIs)
        for elem in pg.cssselect(desired):
            uri = elem.get("src") or elem.get("href") or elem.get("data-download-uri")
            __wait(delay)
            if uri.startswith("http"):
                yield uri
            elif uri.startswith("//"):
                yield uri_base[0] + uri
            elif uri.startswith("/"):
                yield "/".join(uri_base) + uri
            else:
                yield "/".join(uri_base + [uri])
        if nextLink:
            link = nextLink(pg)
            if link and cur_uri != link:
                cur_uri = link
            else:
                cur_uri = False
        else:
            cur_uri = False

##### Internal Utility
def __getHtml(uri, headers=headers, cookies={}):
    return lxml.html.fromstring(requests.get(uri, headers=headers, cookies=cookies).content)

def __wait(secs=False):
    if secs:
        log.info("Waiting: %d", secs)
        time.sleep(secs)

##### Retrievers
def __requestsRetrieve(uri, fname):
    with open(fname, 'wb') as dest:
        dest.write(requests.get(uri, headers=headers).content)

def __curlRetrieve(uri, fname):
    with open(fname, 'wb') as dest:
        dest.write(check_output(["curl", "--socks4", "socks://localhost:9050", uri]))

def __wgetRetrieve(uri, fname):
    call(["wget", "-O", fname, uri])

def __newFromUri(getter, uri, fname=False):
    if not fname:
        fname = uri.split("/")[-1]
    if os.path.exists(fname):
        log.info("Already got: %s", fname)
    else:
        log.info("Getting %s ...", fname)
        getter(uri, fname)
        log.info("Got it")

def __getVid(uri):
    call(["get_flash_videos", "-r", options.quality, uri])

def __getPic(uri):
    __newFromUri(__requestsRetrieve, uri)

def processStream(genOfUris, notify=10, getter=__getPic):
    for i, uri in enumerate(genOfUris):
        if i%notify == 0 and i > 0:
            log.info("Got %d things...", i)
        getter(uri)

####################
##### main thing ###
####################
def main(uri):
    if "youtube" in uri:
        if "list=" in uri:
            log.info("Scraping YouTube playlist...")
            processStream(getStream(uri, "ol.playlist-videos-list > li > a"), __getVid)
        else:
            log.info("Scraping YouTube video...")
            __getVid(uri)
    elif "zero-punctuation" in uri:
        log.info("Scraping Zero Punctuation video...")
        __getVid(uri)
    elif "tumblr" in uri:
        log.info("Scraping tumblr...")
        processStream(getStream(uri, "div.photo_holder img"))
    elif "4chan" in uri:
        log.info("Scraping 4chan thread...")
        processStream(getStream(uri, "a.fileThumb"))

if __name__ == "__main__":
    parser = OptionParser()
    parser.add_option("-v", "--verbose", dest="verbose", default=False, action="store_true",
                      help="If passed, downloads silently")
    parser.add_option("-r", "--quality", dest="quality", default="medium",
                      help="""Specify the quality of downloaded videos. Passed on to get_flash_videos. 
Valid options are:

-   high
-   medium
-   low

-   1080p (1920x1080)
-   720p (1280x720)
-   576p (720x576)
-   480w (854x480)
-   480p (640x480)
-   240w (427x240)
-   240p (320x240)

""")
    (options, args) = parser.parse_args()

    if options.verbose:
        log.setLevel(logging.DEBUG)

    for uri in sys.argv[1:]:
        main(uri)
